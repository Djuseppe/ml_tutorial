{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp linear_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression\n",
    "> This tutorial describes how to fit a curve using linear regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We wish to learn $f:X\\to Y$, where $Y$ is a real number, given $\\{<x^1,y^1>,\\cdots, <x^m,y^m>\\}$.\n",
    "\n",
    "**Approach**\n",
    "\n",
    "1- Choose some parametraized form for $P(Y|X;\\theta)$\n",
    "\n",
    "2- Derive learning algorithms as Maximum Likelihood Estimates (MLE), or Maximum a Posteriori (MAP) estimate for $\\theta$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Linear Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's assume that we are going to predict the price of a house, $y$, based on its square feet, $x$. Therefore, training set = $\\{<x^1,y^1>,\\cdots,<x^m,y^m>\\}$, where:\n",
    "\n",
    "- $m$: number of trainig examples\n",
    "\n",
    "- $x$: input variable\n",
    "\n",
    "- $y$: output variable or target label\n",
    "\n",
    "- $(x^i,y^i)$: is the $i$th training example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/linear_regression_ex.png\" width=\"500\" height=\"500\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would like to find a **line** that **fits** our training examples the **best**.\n",
    "\n",
    "<img src=\"images/linear_regression_ex_model.png\" width=\"500\" height=\"500\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are looling for a line to fit our training set, we need to find a function $\\hat y = f(x)$ that estimates $y^i$ for all $1\\leq i \\leq m$. Thus, we have:\n",
    "\n",
    "$\\hat y = f(x) = w_0 + w_1x$\n",
    "\n",
    "$w_0$ and $w_1$ are the paramaters that we need to find."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cost Function/Error Function\n",
    "\n",
    "We wish to estimate the actual $y$, i.e. we want to minimize the error as much as possible. The error is the difference between the actual $y^i$ and our estimated/predicted $\\hat{y}^i$ for all $1\\leq i \\leq m$. \n",
    "\n",
    "The error/cost function is:\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$J(w_0,w_1) = \\frac{1}{m}\\sum_{i=1}^{m}\\left( \\hat{y}^i - (w_0 + w_1 x^i)\\right)^2$$\n",
    "\n",
    "We get the average of the function squared to make the arithmatic easier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precisely, we need to minimize the **mean residual squared error**:\n",
    "\n",
    "$$\\text{minimize } J(w_0,w_1) = \\underset{\\mathbf{w0,w_1}}{\\arg\\min} \\frac{1}{m}\\sum_{i=1}^{m}\\left( \\hat{y}^i - (w_0 + w_1 x^i)\\right)^2$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting the Linear Regression Model using Gradient Descent Algorithm\n",
    "\n",
    "\n",
    "In order to mininze the cost function, we need to take the gradient (i.e. derivative) of the function with resptect to our parameters $w_0$ and $w_1$, set it zero and solve for $w_0$ and $w_1$.\n",
    " \n",
    " \n",
    "$$\\frac{\\partial{J}}{\\partial{w_0}} = \\frac{-2}{m} \\sum_{i=1}^{m}\\left(\\hat{y}^i - (w_0 + w_1 x^i)\\right)$$\n",
    "\n",
    "$$\\frac{\\partial{J}}{\\partial{w_1}} = \\frac{-2}{m} \\sum_{i=1}^{m}x^i\\left(\\hat{y}^i - (w_0 + w_1 x^i)\\right)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The gradient descent algorithm:\n",
    "\n",
    "initialize $w_0^{(0)} = w_1^{(0)} = 0$, for $t=0$\n",
    "\n",
    "for $t=1$ to *num_iterations*\n",
    "   \n",
    "\n",
    "   \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "$w_0^{(t+1)} = w_0^{(t)} - \\eta \\frac{-2}{m} \\sum_{i=1}^{m}\\left(\\hat{y}^i - (w_0 + w_1 x^i)\\right) $\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "$w_1^{(t+1)} = w_1^{(t)} - \\eta\\frac{-2}{m} \\sum_{i=1}^{m}x^i\\left(\\hat{y}^i - (w_0 + w_1 x^i)\\right)$\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;$t = t+1$\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import altair as alt\n",
    "def generate_data():\n",
    "    \"\"\"It generates dummy data.\"\"\"\n",
    "    noise = np.random.randn(100,1)\n",
    "    X = 2 * np.random.rand(100,1)\n",
    "    y = 5 + 3 * X + noise\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def make_point_plot(x,y):\n",
    "    \"\"\"It plots the point chart of the data\"\"\"\n",
    "    \n",
    "    data_points = pd.DataFrame({'x': x.flatten(), 'y': y.flatten()})\n",
    "    chart = alt.Chart(data_points).mark_point(size=50, color='red',filled=True).encode(\n",
    "        x=\"x\",\n",
    "        y=\"y\"\n",
    "    )\n",
    "    return chart\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def make_line_plot(x,y):\n",
    "    \"\"\"It plots the line chart of the data\"\"\"\n",
    "    \n",
    "    data = pd.DataFrame({'x': x.flatten(), 'y': y.flatten()})\n",
    "    line = alt.Chart(data).mark_line(size=3).encode(\n",
    "        x=\"x\",\n",
    "        y=\"y\"\n",
    "    )\n",
    "    return line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def gradient_descent(data,w_0_t,w_1_t,learning_rate,num_iterations):\n",
    "    \"\"\"Gradient descent implementation, which gets `data`, starting `w_0` and `w_1`, `learning_rate` \n",
    "    and the number of iterations `num_iterations`\"\"\"\n",
    "    \n",
    "    w_0 = 0\n",
    "    w_1 = 0\n",
    "    (X,y) = data\n",
    "    N = len(X)\n",
    "    w_0_t = 0\n",
    "    w_1_t = 0\n",
    "    for t in range(0,num_iterations):\n",
    "        w_0_deriv = np.zeros((N,N))\n",
    "        w_1_deriv = np.zeros((N,N))\n",
    "        w_0_deriv = -2 * (y - (w_0_t + w_1_t * X))\n",
    "        w_1_deriv = -2 * np.dot(X.T, (y - (w_0_t + w_1_t * X)))\n",
    "        w0_sum = np.sum(w_0_deriv,axis=0)\n",
    "        w1_sum = np.sum(w_1_deriv,axis=0)\n",
    "        w_0 = w_0 - learning_rate * (w0_sum / N)\n",
    "        w_1 = w_1 - learning_rate * (w1_sum / N)\n",
    "        w_0_t = w_0\n",
    "        w_1_t = w_1\n",
    "    return w_0, w_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run an Example\n",
    "\n",
    "In this example, we generate some linear-looking data and then find the line that fits the data. The function that we use to generate the data is $y=5+3x+\\text{Gaussian noise}$. Our goal is to find $\\theta=[w_0,w_1]$ where $w_0=5$ and $w_1=3$ or close enough, as we have noise and it makes it impossible to recover the exact paratmeters of the function. We use the `generate_data` function to generate the training data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = generate_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The chart below shows the generated dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div id=\"altair-viz-9cabee521e3c4f6fb76fac67bfd5f1f1\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  (function(spec, embedOpt){\n",
       "    const outputDiv = document.getElementById(\"altair-viz-9cabee521e3c4f6fb76fac67bfd5f1f1\");\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.0.2?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function loadScript(lib) {\n",
       "      return new Promise(function(resolve, reject) {\n",
       "        var s = document.createElement('script');\n",
       "        s.src = paths[lib];\n",
       "        s.async = true;\n",
       "        s.onload = () => resolve(paths[lib]);\n",
       "        s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "        document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "      });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else if (typeof vegaEmbed === \"function\") {\n",
       "      displayChart(vegaEmbed);\n",
       "    } else {\n",
       "      loadScript(\"vega\")\n",
       "        .then(() => loadScript(\"vega-lite\"))\n",
       "        .then(() => loadScript(\"vega-embed\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-62290cb2b2368d21c18ea9d051a8e122\"}, \"mark\": {\"type\": \"point\", \"color\": \"red\", \"filled\": true, \"size\": 50}, \"encoding\": {\"x\": {\"type\": \"quantitative\", \"field\": \"x\"}, \"y\": {\"type\": \"quantitative\", \"field\": \"y\"}}, \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.0.2.json\", \"datasets\": {\"data-62290cb2b2368d21c18ea9d051a8e122\": [{\"x\": 1.358524468110008, \"y\": 9.228579979995512}, {\"x\": 1.9030176478918939, \"y\": 10.367378370848385}, {\"x\": 1.0870544428660738, \"y\": 8.392924015652872}, {\"x\": 0.518112359520817, \"y\": 6.393115926048032}, {\"x\": 0.22319777727516477, \"y\": 5.0724538299535125}, {\"x\": 1.2575773325547845, \"y\": 7.92555542626042}, {\"x\": 0.6427135488637605, \"y\": 7.396307828758524}, {\"x\": 1.7338974420296958, \"y\": 10.688604566212932}, {\"x\": 1.5299054222364008, \"y\": 10.273029272665678}, {\"x\": 0.03676660727914838, \"y\": 3.249024803272783}, {\"x\": 0.03909105859034434, \"y\": 5.680255470126973}, {\"x\": 1.282139746730424, \"y\": 7.706049362773177}, {\"x\": 0.9304995572575323, \"y\": 7.017670751868655}, {\"x\": 0.146672568193565, \"y\": 4.918516683012054}, {\"x\": 0.5325408508257652, \"y\": 7.321935621427186}, {\"x\": 1.678525685480899, \"y\": 10.320877249023662}, {\"x\": 1.610738235777399, \"y\": 9.897470782609814}, {\"x\": 0.09871982409249824, \"y\": 5.6915388469692845}, {\"x\": 0.03925633809737783, \"y\": 4.286085356968344}, {\"x\": 0.41336732921519936, \"y\": 6.857716639284764}, {\"x\": 1.7466990976055299, \"y\": 9.953105153237678}, {\"x\": 1.5980774354385725, \"y\": 7.808915787999145}, {\"x\": 1.2490596968948664, \"y\": 11.131317599588371}, {\"x\": 1.973935107656869, \"y\": 10.156038890821103}, {\"x\": 1.819412545595365, \"y\": 12.14516871175815}, {\"x\": 1.4005317024671828, \"y\": 9.129429503980713}, {\"x\": 0.1505651848267644, \"y\": 3.363746298177757}, {\"x\": 1.6089322809489661, \"y\": 10.628483673056172}, {\"x\": 0.10122050122620085, \"y\": 5.124613891957639}, {\"x\": 1.2617512020920336, \"y\": 9.423680792438367}, {\"x\": 1.4216430745402011, \"y\": 10.742213255919863}, {\"x\": 0.7074162165148379, \"y\": 7.282728733086689}, {\"x\": 1.1576173299730401, \"y\": 9.488077657582634}, {\"x\": 0.7854038378833184, \"y\": 8.322914302825204}, {\"x\": 0.05163405575048485, \"y\": 3.635352965272031}, {\"x\": 0.8786662204085887, \"y\": 6.767174133705226}, {\"x\": 1.7288226807072287, \"y\": 11.226319128186589}, {\"x\": 1.2050185031997909, \"y\": 8.112557193437208}, {\"x\": 1.436319572761862, \"y\": 8.399484305096665}, {\"x\": 0.44242780987389807, \"y\": 7.00488215723115}, {\"x\": 0.7671020339293659, \"y\": 5.382537555686259}, {\"x\": 1.0441370481050338, \"y\": 8.72584076087919}, {\"x\": 1.1985536675072805, \"y\": 6.607340742119261}, {\"x\": 1.7827192394090898, \"y\": 9.35809051375174}, {\"x\": 0.6697498355214377, \"y\": 7.941387822953578}, {\"x\": 1.594738487700106, \"y\": 10.060541669564538}, {\"x\": 0.1444384365549487, \"y\": 8.502642413350133}, {\"x\": 1.8459290918215956, \"y\": 11.038854845595417}, {\"x\": 1.0017904649414908, \"y\": 9.18467721375235}, {\"x\": 1.2242707250908542, \"y\": 9.943226566053323}, {\"x\": 0.5946997665293581, \"y\": 6.772649186768738}, {\"x\": 0.9409123362056411, \"y\": 9.089888098767894}, {\"x\": 1.8644106840323742, \"y\": 9.863213613469416}, {\"x\": 0.1880033919707551, \"y\": 5.495987823367159}, {\"x\": 1.9791108029773783, \"y\": 12.383845264487675}, {\"x\": 1.2634493323380256, \"y\": 7.785843223847415}, {\"x\": 0.745188970187997, \"y\": 8.159254079798735}, {\"x\": 1.704039367365179, \"y\": 9.958763110826819}, {\"x\": 0.12129198862201607, \"y\": 7.104272479777454}, {\"x\": 1.6724794911396668, \"y\": 7.732622020621895}, {\"x\": 1.824042221623438, \"y\": 12.538221274402117}, {\"x\": 1.7195216741561086, \"y\": 10.519953051611168}, {\"x\": 1.099195662126609, \"y\": 8.641986214599397}, {\"x\": 0.4952903002106728, \"y\": 4.301285270187919}, {\"x\": 0.01001827737801464, \"y\": 6.797696046107507}, {\"x\": 1.915363630388622, \"y\": 10.824446450598998}, {\"x\": 1.732557176327852, \"y\": 10.168228475215892}, {\"x\": 1.8424235420938313, \"y\": 10.651976184406978}, {\"x\": 0.23479348577940762, \"y\": 5.62158671309046}, {\"x\": 1.104608538204449, \"y\": 8.109902956530405}, {\"x\": 0.5750180789697399, \"y\": 7.353891258078012}, {\"x\": 0.265402524345405, \"y\": 5.340053599221816}, {\"x\": 1.118545239349448, \"y\": 9.467907849322426}, {\"x\": 0.21780883178823807, \"y\": 7.853413661417226}, {\"x\": 0.9296003748361861, \"y\": 6.9556046763596475}, {\"x\": 1.8044037652006335, \"y\": 11.320950351424067}, {\"x\": 0.37726005321006495, \"y\": 4.359979459181071}, {\"x\": 0.7413217332954116, \"y\": 7.963844963116414}, {\"x\": 1.4708066237598514, \"y\": 8.917842761901028}, {\"x\": 0.3025386717372658, \"y\": 5.733073013052465}, {\"x\": 0.8839610376366933, \"y\": 8.35050716832752}, {\"x\": 0.055374428317988666, \"y\": 6.06415525216673}, {\"x\": 0.3124956372524901, \"y\": 5.676998949330821}, {\"x\": 1.9521374493642414, \"y\": 11.771307664888443}, {\"x\": 0.2905926938863368, \"y\": 6.560782351714301}, {\"x\": 0.9077464190927256, \"y\": 7.621609957723922}, {\"x\": 1.7102975188084242, \"y\": 11.070470860772893}, {\"x\": 0.9347586727596013, \"y\": 7.420911160488571}, {\"x\": 0.6086872205116387, \"y\": 8.889401027024498}, {\"x\": 1.8870612705336016, \"y\": 9.635682870554827}, {\"x\": 1.6822239967095425, \"y\": 9.69992857573989}, {\"x\": 0.4009741629268504, \"y\": 5.542667005890144}, {\"x\": 1.4188425977882975, \"y\": 9.291536800673729}, {\"x\": 0.4203290573615426, \"y\": 3.5067455290566993}, {\"x\": 0.7975429843429152, \"y\": 6.45574117872359}, {\"x\": 0.26955264076201657, \"y\": 6.08155756693448}, {\"x\": 0.3843699950236894, \"y\": 5.952151674011379}, {\"x\": 1.8296096479645632, \"y\": 9.018403802615566}, {\"x\": 0.825816334446456, \"y\": 9.196075934538216}, {\"x\": 0.4682031421613122, \"y\": 6.602492075130366}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#export\n",
    "origin_chart = make_point_plot(X,y)\n",
    "\n",
    "#show the chart\n",
    "origin_chart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set the initial parameters to 0:  $w_0^{(0)} = w_1^{(0)} = 0$, define the number of iterations of the graditent descent algorithm as well as the learning rate. Then, we run the `gradient_descent` function. The outputs of this function are the estimated parameters $w_0$ and $w_1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w_0 = [4.78031942], w_1 = [3.24982313]\n"
     ]
    }
   ],
   "source": [
    "initial_w_0 = 0\n",
    "initial_w_1 = 0\n",
    "num_iterations = 5000\n",
    "learning_rate = 0.001\n",
    "\n",
    "X,y = generate_data()\n",
    "data = (X,y)\n",
    "w_0,w_1 = gradient_descent(data,initial_w_0,initial_w_1,learning_rate,num_iterations)\n",
    "\n",
    "print(\"w_0 = {}, w_1 = {}\".format(w_0,w_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The estimated parameters are $w_0 = 4.795$ and $w_1 = 2.993$ that are close enough to $w_0=5$ and $w_1=3$. Let's plot the line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div id=\"altair-viz-ce20d3cf7b5e4a54aea9f94dea01180d\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  (function(spec, embedOpt){\n",
       "    const outputDiv = document.getElementById(\"altair-viz-ce20d3cf7b5e4a54aea9f94dea01180d\");\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.0.2?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function loadScript(lib) {\n",
       "      return new Promise(function(resolve, reject) {\n",
       "        var s = document.createElement('script');\n",
       "        s.src = paths[lib];\n",
       "        s.async = true;\n",
       "        s.onload = () => resolve(paths[lib]);\n",
       "        s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "        document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "      });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else if (typeof vegaEmbed === \"function\") {\n",
       "      displayChart(vegaEmbed);\n",
       "    } else {\n",
       "      loadScript(\"vega\")\n",
       "        .then(() => loadScript(\"vega-lite\"))\n",
       "        .then(() => loadScript(\"vega-embed\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"layer\": [{\"data\": {\"name\": \"data-ec3aa42d3bc1761d7304f0d2692077c1\"}, \"mark\": {\"type\": \"point\", \"color\": \"red\", \"filled\": true, \"size\": 50}, \"encoding\": {\"x\": {\"type\": \"quantitative\", \"field\": \"x\"}, \"y\": {\"type\": \"quantitative\", \"field\": \"y\"}}}, {\"data\": {\"name\": \"data-8039c0fe67937d5987e4f5c7a2a55e0a\"}, \"mark\": {\"type\": \"line\", \"size\": 3}, \"encoding\": {\"x\": {\"type\": \"quantitative\", \"field\": \"x\"}, \"y\": {\"type\": \"quantitative\", \"field\": \"y\"}}}], \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.0.2.json\", \"datasets\": {\"data-ec3aa42d3bc1761d7304f0d2692077c1\": [{\"x\": 1.227286173294534, \"y\": 9.665512752840543}, {\"x\": 0.9457084445212269, \"y\": 7.7588977362171185}, {\"x\": 1.2286805036931587, \"y\": 10.981437074857219}, {\"x\": 0.019950032584719724, \"y\": 5.74952362414664}, {\"x\": 0.7275227844247734, \"y\": 7.625126112582706}, {\"x\": 1.6347975536846813, \"y\": 8.623474819378202}, {\"x\": 0.9799456261562081, \"y\": 6.966826316122734}, {\"x\": 1.4940038265019393, \"y\": 9.933041455491956}, {\"x\": 1.697761410331346, \"y\": 10.441827595933816}, {\"x\": 1.5149446772148045, \"y\": 9.741147623008272}, {\"x\": 0.5015558816842991, \"y\": 7.090252926440994}, {\"x\": 0.6316629744732951, \"y\": 6.15001498078484}, {\"x\": 1.1695060071269896, \"y\": 7.242465983559393}, {\"x\": 0.7365346701296762, \"y\": 7.02286333617488}, {\"x\": 1.8363145966675603, \"y\": 9.85501292394825}, {\"x\": 0.7681356101325363, \"y\": 7.161500473345529}, {\"x\": 0.17168084746952395, \"y\": 4.038438950541313}, {\"x\": 0.549927178320051, \"y\": 6.395584441729569}, {\"x\": 0.03905610556480266, \"y\": 6.315343067798485}, {\"x\": 1.4536745008839325, \"y\": 10.349084415942176}, {\"x\": 1.205221915506159, \"y\": 9.555778850532864}, {\"x\": 1.601378290829979, \"y\": 8.165159642701921}, {\"x\": 1.4125327843891498, \"y\": 9.909436652582944}, {\"x\": 0.6931033320811921, \"y\": 7.287767491024033}, {\"x\": 0.705764875223424, \"y\": 6.433636238323218}, {\"x\": 0.30700408932875023, \"y\": 6.941302535244839}, {\"x\": 1.7670895888753992, \"y\": 9.454384494501888}, {\"x\": 0.08714301762173338, \"y\": 5.370200438632895}, {\"x\": 0.6560626156237002, \"y\": 6.185089393120842}, {\"x\": 1.17855971331312, \"y\": 8.828489361749334}, {\"x\": 0.8146371190101462, \"y\": 6.04907585681462}, {\"x\": 0.7054133263971556, \"y\": 7.729513041015943}, {\"x\": 1.3662853854880348, \"y\": 9.774685257715893}, {\"x\": 1.6371625303369957, \"y\": 9.88006076070937}, {\"x\": 1.1593595057947212, \"y\": 7.292580575153441}, {\"x\": 0.0671759266731522, \"y\": 4.371443064022728}, {\"x\": 1.955865014127949, \"y\": 10.690692265261383}, {\"x\": 0.1002563881277716, \"y\": 6.384867827668412}, {\"x\": 1.7346095783318223, \"y\": 9.939958684790605}, {\"x\": 1.7165992742174936, \"y\": 9.314388819025766}, {\"x\": 1.4874745976159556, \"y\": 8.81428706509551}, {\"x\": 1.7595365977815058, \"y\": 8.484544243922043}, {\"x\": 1.157253367860248, \"y\": 7.966723485472539}, {\"x\": 0.09038310227499147, \"y\": 4.624685300498679}, {\"x\": 1.4980011638184756, \"y\": 9.620914948643353}, {\"x\": 1.5750747142175598, \"y\": 8.829620913557958}, {\"x\": 1.5665555521151766, \"y\": 10.006487678399653}, {\"x\": 1.7275297976449178, \"y\": 11.008684069182708}, {\"x\": 1.3460075926419637, \"y\": 8.717519135931239}, {\"x\": 0.23065970464235575, \"y\": 5.432812390684559}, {\"x\": 1.3042336578526483, \"y\": 8.202889425426928}, {\"x\": 1.714849797594641, \"y\": 11.527652761146957}, {\"x\": 0.9346202162766282, \"y\": 9.38424866917903}, {\"x\": 0.42882660404884865, \"y\": 6.275773069858629}, {\"x\": 1.9243722727625636, \"y\": 10.997594115852664}, {\"x\": 0.4467874075449989, \"y\": 7.289273266121791}, {\"x\": 0.6902632695742097, \"y\": 7.189566721740488}, {\"x\": 1.2538010324394882, \"y\": 8.949935827951013}, {\"x\": 1.8993511018108293, \"y\": 11.159802766194218}, {\"x\": 0.5922236092697333, \"y\": 7.5517973158406395}, {\"x\": 0.6471829236581839, \"y\": 5.581377501612102}, {\"x\": 1.0019830115538277, \"y\": 7.543402144763208}, {\"x\": 1.4940281300567217, \"y\": 8.370941750784935}, {\"x\": 1.4050778218310527, \"y\": 10.30848269672649}, {\"x\": 1.6600298379116696, \"y\": 9.676802790251466}, {\"x\": 0.29038747550195665, \"y\": 4.866940541052434}, {\"x\": 1.0606337190092372, \"y\": 6.908310199034153}, {\"x\": 1.5361039835170802, \"y\": 9.341972476343988}, {\"x\": 1.5113236484475514, \"y\": 8.156908247071012}, {\"x\": 0.8558940122370411, \"y\": 8.134405732518095}, {\"x\": 1.22919129834512, \"y\": 8.357777584406382}, {\"x\": 0.908977317930368, \"y\": 5.5799268158343835}, {\"x\": 1.4897517468348305, \"y\": 8.583383617686412}, {\"x\": 0.5895885323291306, \"y\": 5.373944514759531}, {\"x\": 1.8660397625583314, \"y\": 10.390281970792817}, {\"x\": 0.5799060445612132, \"y\": 8.335593718769568}, {\"x\": 1.727695711867401, \"y\": 10.648062305869168}, {\"x\": 1.7976065443284965, \"y\": 11.0296444926949}, {\"x\": 0.7914029702106316, \"y\": 9.188662068768906}, {\"x\": 1.4662208770456084, \"y\": 9.115655094802829}, {\"x\": 1.6010340147536124, \"y\": 9.84034943500281}, {\"x\": 1.7394926161398274, \"y\": 10.722891720215111}, {\"x\": 0.4280820486532644, \"y\": 6.818223573480756}, {\"x\": 1.639106005166139, \"y\": 8.857354431722138}, {\"x\": 0.6597877047166318, \"y\": 7.460314882804245}, {\"x\": 0.5416043866290656, \"y\": 5.191311660951506}, {\"x\": 1.1923478548620792, \"y\": 9.652392314935572}, {\"x\": 1.0313838298157438, \"y\": 8.880741168048262}, {\"x\": 1.6393601481949671, \"y\": 11.569310547974252}, {\"x\": 0.47796430417767666, \"y\": 6.672636352534994}, {\"x\": 0.37444587604316504, \"y\": 5.610895591765524}, {\"x\": 0.8936011658847991, \"y\": 8.567446856993758}, {\"x\": 1.8088634174023475, \"y\": 12.019514384261148}, {\"x\": 1.626426012616154, \"y\": 9.385954377207964}, {\"x\": 1.5592356176113822, \"y\": 10.118806421884157}, {\"x\": 1.7208401215450422, \"y\": 9.033808242423797}, {\"x\": 0.14068093126168746, \"y\": 4.853634859658708}, {\"x\": 0.047974622733929495, \"y\": 5.944401711216808}, {\"x\": 0.0959686011397507, \"y\": 4.000557522503156}, {\"x\": 0.4300592249120416, \"y\": 5.308361432455483}], \"data-8039c0fe67937d5987e4f5c7a2a55e0a\": [{\"x\": 1.358524468110008, \"y\": 9.195283651687774}, {\"x\": 1.9030176478918939, \"y\": 10.96479018020387}, {\"x\": 1.0870544428660738, \"y\": 8.313054085179708}, {\"x\": 0.518112359520817, \"y\": 6.46409294441709}, {\"x\": 0.22319777727516477, \"y\": 5.505672714346763}, {\"x\": 1.2575773325547845, \"y\": 8.867223315887935}, {\"x\": 0.6427135488637605, \"y\": 6.869024771279513}, {\"x\": 1.7338974420296958, \"y\": 10.415179423835859}, {\"x\": 1.5299054222364008, \"y\": 9.752241440050614}, {\"x\": 0.03676660727914838, \"y\": 4.899804386374329}, {\"x\": 0.03909105859034434, \"y\": 4.907358442004607}, {\"x\": 1.282139746730424, \"y\": 8.947046817547443}, {\"x\": 0.9304995572575323, \"y\": 7.804278397178665}, {\"x\": 0.146672568193565, \"y\": 5.256979320023268}, {\"x\": 0.5325408508257652, \"y\": 6.510982989157358}, {\"x\": 1.678525685480899, \"y\": 10.235231008783629}, {\"x\": 1.610738235777399, \"y\": 10.014933786971135}, {\"x\": 0.09871982409249824, \"y\": 5.101141383208174}, {\"x\": 0.03925633809737783, \"y\": 4.907895571169094}, {\"x\": 0.41336732921519936, \"y\": 6.123690122420948}, {\"x\": 1.7466990976055299, \"y\": 10.456782540198725}, {\"x\": 1.5980774354385725, \"y\": 9.973788425215151}, {\"x\": 1.2490596968948664, \"y\": 8.83954250652723}, {\"x\": 1.973935107656869, \"y\": 11.195259381103998}, {\"x\": 1.819412545595365, \"y\": 10.693088385169034}, {\"x\": 1.4005317024671828, \"y\": 9.331799733431355}, {\"x\": 0.1505651848267644, \"y\": 5.26962963558501}, {\"x\": 1.6089322809489661, \"y\": 10.009064753202159}, {\"x\": 0.10122050122620085, \"y\": 5.109268141592127}, {\"x\": 1.2617512020920336, \"y\": 8.880787653641981}, {\"x\": 1.4216430745402011, \"y\": 9.400407958651186}, {\"x\": 0.7074162165148379, \"y\": 7.079296997034208}, {\"x\": 1.1576173299730401, \"y\": 8.5423709876554}, {\"x\": 0.7854038378833184, \"y\": 7.332742972629804}, {\"x\": 0.05163405575048485, \"y\": 4.948120964265984}, {\"x\": 0.8786662204085887, \"y\": 7.635829220302435}, {\"x\": 1.7288226807072287, \"y\": 10.398687347122678}, {\"x\": 1.2050185031997909, \"y\": 8.696416416686588}, {\"x\": 1.436319572761862, \"y\": 9.448103982005211}, {\"x\": 0.44242780987389807, \"y\": 6.218131544566918}, {\"x\": 0.7671020339293659, \"y\": 7.273265346862088}, {\"x\": 1.0441370481050338, \"y\": 8.173580143105752}, {\"x\": 1.1985536675072805, \"y\": 8.675406844136454}, {\"x\": 1.7827192394090898, \"y\": 10.573841630094043}, {\"x\": 0.6697498355214377, \"y\": 6.956887920946064}, {\"x\": 1.594738487700106, \"y\": 9.962937435632586}, {\"x\": 0.1444384365549487, \"y\": 5.2497187873538245}, {\"x\": 1.8459290918215956, \"y\": 10.779262470361083}, {\"x\": 1.0017904649414908, \"y\": 8.035961237762887}, {\"x\": 1.2242707250908542, \"y\": 8.758982732647285}, {\"x\": 0.5946997665293581, \"y\": 6.712988471002052}, {\"x\": 0.9409123362056411, \"y\": 7.838118087027588}, {\"x\": 1.8644106840323742, \"y\": 10.839324376163917}, {\"x\": 0.1880033919707551, \"y\": 5.3912971870202115}, {\"x\": 1.9791108029773783, \"y\": 11.212079475458385}, {\"x\": 1.2634493323380256, \"y\": 8.88630627658921}, {\"x\": 0.745188970187997, \"y\": 7.202051765517186}, {\"x\": 1.704039367365179, \"y\": 10.318145962243285}, {\"x\": 0.12129198862201607, \"y\": 5.174496925537871}, {\"x\": 1.6724794911396668, \"y\": 10.215581946579078}, {\"x\": 1.824042221623438, \"y\": 10.708134013398706}, {\"x\": 1.7195216741561086, \"y\": 10.368460720922197}, {\"x\": 1.099195662126609, \"y\": 8.35251090033076}, {\"x\": 0.4952903002106728, \"y\": 6.389925288249828}, {\"x\": 0.01001827737801464, \"y\": 4.812877045234962}, {\"x\": 1.915363630388622, \"y\": 11.004912439655598}, {\"x\": 1.732557176327852, \"y\": 10.410823797360779}, {\"x\": 1.8424235420938313, \"y\": 10.767870053780584}, {\"x\": 0.23479348577940762, \"y\": 5.543356716025621}, {\"x\": 1.104608538204449, \"y\": 8.37010179019576}, {\"x\": 0.5750180789697399, \"y\": 6.649026467579145}, {\"x\": 0.265402524345405, \"y\": 5.642830677473274}, {\"x\": 1.118545239349448, \"y\": 8.415393603900263}, {\"x\": 0.21780883178823807, \"y\": 5.488159594669573}, {\"x\": 0.9296003748361861, \"y\": 7.801356213349775}, {\"x\": 1.8044037652006335, \"y\": 10.644312503524052}, {\"x\": 0.37726005321006495, \"y\": 6.006347861782142}, {\"x\": 0.7413217332954116, \"y\": 7.189483929623466}, {\"x\": 1.4708066237598514, \"y\": 9.560180797943762}, {\"x\": 0.3025386717372658, \"y\": 5.763516588140066}, {\"x\": 0.8839610376366933, \"y\": 7.6530364397871375}, {\"x\": 0.055374428317988666, \"y\": 4.960276513541976}, {\"x\": 0.3124956372524901, \"y\": 5.795874964952897}, {\"x\": 1.9521374493642414, \"y\": 11.124420847055475}, {\"x\": 0.2905926938863368, \"y\": 5.724694273037431}, {\"x\": 0.9077464190927256, \"y\": 7.730334722543507}, {\"x\": 1.7102975188084242, \"y\": 10.338483847540033}, {\"x\": 0.9347586727596013, \"y\": 7.818119769240725}, {\"x\": 0.6086872205116387, \"y\": 6.7584452224509475}, {\"x\": 1.8870612705336016, \"y\": 10.912934776030994}, {\"x\": 1.6822239967095425, \"y\": 10.247249866147811}, {\"x\": 0.4009741629268504, \"y\": 6.083414523991958}, {\"x\": 1.4188425977882975, \"y\": 9.391306904534336}, {\"x\": 0.4203290573615426, \"y\": 6.146314507559515}, {\"x\": 0.7975429843429152, \"y\": 7.372193051544427}, {\"x\": 0.26955264076201657, \"y\": 5.656317821786519}, {\"x\": 0.3843699950236894, \"y\": 6.029453915124478}, {\"x\": 1.8296096479645632, \"y\": 10.726227164283717}, {\"x\": 0.825816334446456, \"y\": 7.464076438607746}, {\"x\": 0.4682031421613122, \"y\": 6.301896815558047}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.LayerChart(...)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predicted = w_0 + w_1 * X\n",
    "line = make_line_plot(X,y_predicted)\n",
    "\n",
    "#show the charts\n",
    "origin_chart + line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning_rate: 0.0010 => w_0 = [4.79512391], w_1 = [3.14337243]\n",
      "learning_rate: 0.1000 => w_0 = [5.18617284], w_1 = [2.8127775]\n",
      "learning_rate: 0.2000 => w_0 = [5.18617284], w_1 = [2.8127775]\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "initial_w_0 = 0\n",
    "initial_w_1 = 0\n",
    "num_iterations = 5000\n",
    "l_rates = [0.001, 0.1,0.2]\n",
    "learning_rate = 0.001\n",
    "all_params = []\n",
    "\n",
    "X,y = generate_data()\n",
    "data = (X,y)\n",
    "for i in range(0,len(l_rates)):\n",
    "    learning_rate = l_rates[i]\n",
    "    w_0,w_1 = gradient_descent(data,initial_w_0,initial_w_1,learning_rate,num_iterations)\n",
    "    all_params.append((w_0,w_1))\n",
    "    print(\"learning_rate: {:.4f} => w_0 = {}, w_1 = {}\".format(learning_rate,w_0,w_1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
