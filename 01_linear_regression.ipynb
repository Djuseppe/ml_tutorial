{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp linear_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression\n",
    "> This tutorial describes how to fit a curve using linear regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We wish to learn $f:X\\to Y$, where $Y$ is a real number, given $\\{<x^1,y^1>,\\cdots, <x^m,y^m>\\}$.\n",
    "\n",
    "**Approach**\n",
    "\n",
    "1- Choose some parametraized form for $P(Y|X;\\theta)$\n",
    "\n",
    "2- Derive learning algorithms as Maximum Likelihood Estimates (MLE), or Maximum a Posteriori (MAP) estimate for $\\theta$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Linear Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's assume that we are going to predict the price of a house, $y$, based on its square feet, $x$. Therefore, training set = $\\{<x^1,y^1>,\\cdots,<x^m,y^m>\\}$, where:\n",
    "\n",
    "- $m$: number of trainig examples\n",
    "\n",
    "- $x$: input variable\n",
    "\n",
    "- $y$: output variable or target label\n",
    "\n",
    "- $(x^i,y^i)$: is the $i$th training example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/linear_regression_ex.png\" width=\"500\" height=\"500\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would like to find a **line** that **fits** our training examples the **best**.\n",
    "\n",
    "<img src=\"images/linear_regression_ex_model.png\" width=\"500\" height=\"500\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are looling for a line to fit our training set, we need to find a function $\\hat y = f(x)$ that estimates $y^i$ for all $1\\leq i \\leq m$. Thus, we have:\n",
    "\n",
    "$\\hat y = f(x) = w_0 + w_1x$\n",
    "\n",
    "$w_0$ and $w_1$ are the paramaters that we need to find."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cost Function/Error Function\n",
    "\n",
    "We wish to estimate the actual $y$, i.e. we want to minimize the error as much as possible. The error is the difference between the actual $y^i$ and our estimated/predicted $\\hat{y}^i$ for all $1\\leq i \\leq m$. \n",
    "\n",
    "The error/cost function is:\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$J(w_0,w_1) = \\frac{1}{m}\\sum_{i=1}^{m}\\left( \\hat{y}^i - (w_0 + w_1 x^i)\\right)^2$$\n",
    "\n",
    "We get the average of the function squared to make the arithmatic easier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precisely, we need to minimize the **mean residual squared error**:\n",
    "\n",
    "$$\\text{minimize } J(w_0,w_1) = \\underset{\\mathbf{w0,w_1}}{\\arg\\min} \\frac{1}{m}\\sum_{i=1}^{m}\\left( \\hat{y}^i - (w_0 + w_1 x^i)\\right)^2$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting the Linear Regression Model using Gradient Descent Algorithm\n",
    "\n",
    "\n",
    "In order to mininze the cost function, we need to take the gradient (i.e. derivative) of the function with resptect to our parameters $w_0$ and $w_1$, set it zero and solve for $w_0$ and $w_1$.\n",
    " \n",
    " \n",
    "$$\\frac{\\partial{J}}{\\partial{w_0}} = \\frac{-2}{m} \\sum_{i=1}^{m}\\left(\\hat{y}^i - (w_0 + w_1 x^i)\\right)$$\n",
    "\n",
    "$$\\frac{\\partial{J}}{\\partial{w_1}} = \\frac{-2}{m} \\sum_{i=1}^{m}x^i\\left(\\hat{y}^i - (w_0 + w_1 x^i)\\right)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The gradient descent algorithm:\n",
    "\n",
    "initialize $w_0^{(0)} = w_1^{(0)} = 0$, for $t=0$\n",
    "\n",
    "for $t=1$ to *num_iterations*\n",
    "   \n",
    "\n",
    "   \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "$w_0^{(t+1)} = w_0^{(t)} - \\eta \\frac{-2}{m} \\sum_{i=1}^{m}\\left(\\hat{y}^i - (w_0 + w_1 x^i)\\right) $\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "$w_1^{(t+1)} = w_1^{(t)} - \\eta\\frac{-2}{m} \\sum_{i=1}^{m}x^i\\left(\\hat{y}^i - (w_0 + w_1 x^i)\\right)$\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;$t = t+1$\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import altair as alt\n",
    "def generate_data():\n",
    "    \"\"\"It generates dummy data.\"\"\"\n",
    "    noise = np.random.randn(100,1)\n",
    "    X = 2 * np.random.rand(100,1)\n",
    "    y = 5 + 3 * X + noise\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def make_point_plot(x,y):\n",
    "    \"\"\"It plots the point chart of the data\"\"\"\n",
    "    \n",
    "    data_points = pd.DataFrame({'x': x.flatten(), 'y': y.flatten()})\n",
    "    chart = alt.Chart(data_points).mark_point(size=50, color='red',filled=True).encode(\n",
    "        x=\"x\",\n",
    "        y=\"y\"\n",
    "    )\n",
    "    return chart\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def make_line_plot(x,y):\n",
    "    \"\"\"It plots the line chart of the data\"\"\"\n",
    "    \n",
    "    data = pd.DataFrame({'x': x.flatten(), 'y': y.flatten()})\n",
    "    line = alt.Chart(data).mark_line(size=3).encode(\n",
    "        x=\"x\",\n",
    "        y=\"y\"\n",
    "    )\n",
    "    return line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def gradient_descent(data,w_0_t,w_1_t,learning_rate,num_iterations):\n",
    "    \"\"\"Gradient descent implementation, which gets `data`, starting `w_0` and `w_1`, `learning_rate` \n",
    "    and the number of iterations `num_iterations`\"\"\"\n",
    "    \n",
    "    w_0 = 0\n",
    "    w_1 = 0\n",
    "    (X,y) = data\n",
    "    N = len(X)\n",
    "    w_0_t = 0\n",
    "    w_1_t = 0\n",
    "    for t in range(0,num_iterations):\n",
    "        w_0_deriv = np.zeros((N,N))\n",
    "        w_1_deriv = np.zeros((N,N))\n",
    "        w_0_deriv = -2 * (y - (w_0_t + w_1_t * X))\n",
    "        w_1_deriv = -2 * np.dot(X.T, (y - (w_0_t + w_1_t * X)))\n",
    "        w0_sum = np.sum(w_0_deriv,axis=0)\n",
    "        w1_sum = np.sum(w_1_deriv,axis=0)\n",
    "        w_0 = w_0 - learning_rate * (w0_sum / N)\n",
    "        w_1 = w_1 - learning_rate * (w1_sum / N)\n",
    "        w_0_t = w_0\n",
    "        w_1_t = w_1\n",
    "    return w_0, w_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run an Example\n",
    "\n",
    "In this example, we generate some linear-looking data and then find the line that fits the data. The function that we use to generate the data is $y=5+3x+\\text{Gaussian noise}$. Our goal is to find $\\theta=[w_0,w_1]$ where $w_0=5$ and $w_1=3$ or close enough, as we have noise and it makes it impossible to recover the exact paratmeters of the function. We use the `generate_data` function to generate the training data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = generate_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The chart below shows the generated dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div id=\"altair-viz-11228faa2c3a4d3d95f57f837af61ef8\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  (function(spec, embedOpt){\n",
       "    const outputDiv = document.getElementById(\"altair-viz-11228faa2c3a4d3d95f57f837af61ef8\");\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.0.2?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function loadScript(lib) {\n",
       "      return new Promise(function(resolve, reject) {\n",
       "        var s = document.createElement('script');\n",
       "        s.src = paths[lib];\n",
       "        s.async = true;\n",
       "        s.onload = () => resolve(paths[lib]);\n",
       "        s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "        document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "      });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else if (typeof vegaEmbed === \"function\") {\n",
       "      displayChart(vegaEmbed);\n",
       "    } else {\n",
       "      loadScript(\"vega\")\n",
       "        .then(() => loadScript(\"vega-lite\"))\n",
       "        .then(() => loadScript(\"vega-embed\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-13c2892f2906ceb3885f6de89a3b3e60\"}, \"mark\": {\"type\": \"point\", \"color\": \"red\", \"filled\": true, \"size\": 50}, \"encoding\": {\"x\": {\"type\": \"quantitative\", \"field\": \"x\"}, \"y\": {\"type\": \"quantitative\", \"field\": \"y\"}}, \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.0.2.json\", \"datasets\": {\"data-13c2892f2906ceb3885f6de89a3b3e60\": [{\"x\": 1.2198006438212339, \"y\": 9.201309707614168}, {\"x\": 1.0897044579970108, \"y\": 8.988191404987854}, {\"x\": 1.647915378046081, \"y\": 11.039626753418785}, {\"x\": 0.830754576670381, \"y\": 8.669865959097304}, {\"x\": 1.247934639247546, \"y\": 7.055090668327976}, {\"x\": 1.8784413299081755, \"y\": 9.890102030419008}, {\"x\": 0.30666817692531123, \"y\": 5.993787706951248}, {\"x\": 0.7116737577124599, \"y\": 6.196781520676983}, {\"x\": 0.5756569584079447, \"y\": 7.2869130583089134}, {\"x\": 1.4352606501780347, \"y\": 8.309427576033714}, {\"x\": 1.767103017904752, \"y\": 10.642051478293089}, {\"x\": 0.7118426875907331, \"y\": 9.6167838599892}, {\"x\": 0.12438050181328775, \"y\": 4.401919801423636}, {\"x\": 0.9982397744305924, \"y\": 8.24403141939456}, {\"x\": 1.7141023297708997, \"y\": 9.74693805585004}, {\"x\": 1.8900577994251766, \"y\": 6.6114601366188515}, {\"x\": 1.4223177711064057, \"y\": 9.634834054599406}, {\"x\": 0.32345866470797024, \"y\": 6.928043825913341}, {\"x\": 1.7655306720840656, \"y\": 9.953675160169832}, {\"x\": 0.8205797747328056, \"y\": 5.399592468327233}, {\"x\": 0.2690463843354891, \"y\": 4.802873010563867}, {\"x\": 0.7722475581531809, \"y\": 6.8725038104328435}, {\"x\": 1.4251189255451808, \"y\": 8.678591024590029}, {\"x\": 0.31282293489725466, \"y\": 6.170455207309783}, {\"x\": 0.2707676989516312, \"y\": 6.3991741677388205}, {\"x\": 1.522111679038506, \"y\": 9.107477345313141}, {\"x\": 1.7190735530460701, \"y\": 10.27623021408875}, {\"x\": 0.6460228150758589, \"y\": 6.542518425317097}, {\"x\": 0.44649166668561935, \"y\": 6.824901005700212}, {\"x\": 0.04997014227792085, \"y\": 3.6161333337262636}, {\"x\": 0.13945835146489527, \"y\": 4.634725050875814}, {\"x\": 1.0571551535903374, \"y\": 8.647070111819207}, {\"x\": 1.1588326938410958, \"y\": 8.877342538170389}, {\"x\": 0.3468221941989884, \"y\": 5.348965073340407}, {\"x\": 0.3132277837066968, \"y\": 5.634875804963522}, {\"x\": 1.2803475505588953, \"y\": 8.38896137439582}, {\"x\": 1.947148252253836, \"y\": 11.79781393703604}, {\"x\": 0.9343604765342854, \"y\": 8.940008748804328}, {\"x\": 1.3832212317540828, \"y\": 9.418855733930007}, {\"x\": 1.6176122752614621, \"y\": 9.338625853114511}, {\"x\": 1.0712594539503713, \"y\": 8.000115594584228}, {\"x\": 0.09143371154541535, \"y\": 5.313392599937331}, {\"x\": 0.8802188478435917, \"y\": 7.665412601537694}, {\"x\": 0.38261287581822145, \"y\": 5.224774378956612}, {\"x\": 0.04514322074058508, \"y\": 5.043907031848995}, {\"x\": 0.313967450268551, \"y\": 5.101486327504374}, {\"x\": 1.9904703075225654, \"y\": 13.128368706597755}, {\"x\": 1.1617115903376714, \"y\": 8.81444090969501}, {\"x\": 0.371149354523026, \"y\": 7.360208390795372}, {\"x\": 1.364981800228181, \"y\": 11.881631147300428}, {\"x\": 0.6128147933377939, \"y\": 5.036932053973047}, {\"x\": 1.2041538386060704, \"y\": 8.737046233368327}, {\"x\": 1.9360367505416942, \"y\": 11.650897773191687}, {\"x\": 0.03587424236028225, \"y\": 5.126181481596323}, {\"x\": 1.2383913994373215, \"y\": 7.047096863610438}, {\"x\": 0.9568550997491556, \"y\": 9.209393762014056}, {\"x\": 0.3805935065017181, \"y\": 6.556019675236521}, {\"x\": 0.06789577994039675, \"y\": 5.372393540768756}, {\"x\": 1.5055217135952133, \"y\": 8.502056660172894}, {\"x\": 0.6062316833329984, \"y\": 7.587850304688638}, {\"x\": 0.23769956576017925, \"y\": 4.835612001670793}, {\"x\": 1.373322723768607, \"y\": 6.8897234764072}, {\"x\": 0.8628842151812319, \"y\": 7.591318766022762}, {\"x\": 1.266971057474008, \"y\": 10.53057792495669}, {\"x\": 0.8427899496786673, \"y\": 7.673823883905783}, {\"x\": 1.9282021083342769, \"y\": 9.497892050663507}, {\"x\": 0.9038766130523939, \"y\": 7.93054175883963}, {\"x\": 0.8169006223780093, \"y\": 6.238238000585394}, {\"x\": 0.5764623603116261, \"y\": 5.3998303950314925}, {\"x\": 1.0420891789427964, \"y\": 9.206261607808681}, {\"x\": 1.5658774575523624, \"y\": 10.371693813619766}, {\"x\": 1.2916045873357813, \"y\": 9.359101936577835}, {\"x\": 1.831034093971852, \"y\": 10.840268904047555}, {\"x\": 0.015359486297369385, \"y\": 4.0692996970530135}, {\"x\": 0.5709712400181342, \"y\": 7.3276024588605}, {\"x\": 0.45982787985227813, \"y\": 5.1285859390597315}, {\"x\": 0.21010815539860572, \"y\": 4.979052314875355}, {\"x\": 0.38169112463535093, \"y\": 7.964711025368801}, {\"x\": 0.35309262182960643, \"y\": 6.911893199961103}, {\"x\": 0.1427402436935572, \"y\": 4.938240543302635}, {\"x\": 0.11626937985199937, \"y\": 6.182764627334548}, {\"x\": 1.7458596578007934, \"y\": 11.220598781658415}, {\"x\": 1.3553788600217513, \"y\": 9.616594880840251}, {\"x\": 1.0238022711574408, \"y\": 7.537710035962981}, {\"x\": 1.0650452789656912, \"y\": 9.24703675446977}, {\"x\": 0.9011133531050313, \"y\": 9.99663419852156}, {\"x\": 0.6008943986905146, \"y\": 7.44714647847754}, {\"x\": 1.6547190961626594, \"y\": 10.592220136863482}, {\"x\": 0.701048512164095, \"y\": 6.91471000143212}, {\"x\": 0.781440423703031, \"y\": 8.182840990386534}, {\"x\": 1.1680560593349874, \"y\": 9.08356524757865}, {\"x\": 0.5345180842656405, \"y\": 5.678030284191532}, {\"x\": 1.9899226868555397, \"y\": 12.082429083434846}, {\"x\": 1.6784449087881446, \"y\": 9.526028280375284}, {\"x\": 0.7824337486836277, \"y\": 8.680963741675596}, {\"x\": 1.5993979741970388, \"y\": 9.008775113159007}, {\"x\": 1.5958510521304072, \"y\": 11.64983449009849}, {\"x\": 1.4362883815501675, \"y\": 8.93087037865868}, {\"x\": 1.7656458451816255, \"y\": 8.81774720103989}, {\"x\": 0.5750490335196048, \"y\": 5.863001879829589}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "origin_chart = make_point_plot(X,y)\n",
    "\n",
    "#show the chart\n",
    "origin_chart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set the initial parameters to 0:  $w_0^{(0)} = w_1^{(0)} = 0$, define the number of iterations of the graditent descent algorithm as well as the learning rate. Then, we run the `gradient_descent` function. The outputs of this function are the estimated parameters $w_0$ and $w_1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w_0 = [4.65664658], w_1 = [3.33942319]\n"
     ]
    }
   ],
   "source": [
    "initial_w_0 = 0\n",
    "initial_w_1 = 0\n",
    "num_iterations = 5000\n",
    "learning_rate = 0.001\n",
    "\n",
    "# X,y = generate_data()\n",
    "data = (X,y)\n",
    "w_0,w_1 = gradient_descent(data,initial_w_0,initial_w_1,learning_rate,num_iterations)\n",
    "\n",
    "print(\"w_0 = {}, w_1 = {}\".format(w_0,w_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The estimated parameters are $w_0 = 4.656$ and $w_1 = 3.339$ that are close enough to $w_0=5$ and $w_1=3$. Let's plot the line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div id=\"altair-viz-e703110b91ee49089d7b9bedf615937d\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  (function(spec, embedOpt){\n",
       "    const outputDiv = document.getElementById(\"altair-viz-e703110b91ee49089d7b9bedf615937d\");\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.0.2?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function loadScript(lib) {\n",
       "      return new Promise(function(resolve, reject) {\n",
       "        var s = document.createElement('script');\n",
       "        s.src = paths[lib];\n",
       "        s.async = true;\n",
       "        s.onload = () => resolve(paths[lib]);\n",
       "        s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "        document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "      });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else if (typeof vegaEmbed === \"function\") {\n",
       "      displayChart(vegaEmbed);\n",
       "    } else {\n",
       "      loadScript(\"vega\")\n",
       "        .then(() => loadScript(\"vega-lite\"))\n",
       "        .then(() => loadScript(\"vega-embed\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"layer\": [{\"data\": {\"name\": \"data-13c2892f2906ceb3885f6de89a3b3e60\"}, \"mark\": {\"type\": \"point\", \"color\": \"red\", \"filled\": true, \"size\": 50}, \"encoding\": {\"x\": {\"type\": \"quantitative\", \"field\": \"x\"}, \"y\": {\"type\": \"quantitative\", \"field\": \"y\"}}}, {\"data\": {\"name\": \"data-d1fb7a47d11daad6673ec7b1705f5f63\"}, \"mark\": {\"type\": \"line\", \"size\": 3}, \"encoding\": {\"x\": {\"type\": \"quantitative\", \"field\": \"x\"}, \"y\": {\"type\": \"quantitative\", \"field\": \"y\"}}}], \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.0.2.json\", \"datasets\": {\"data-13c2892f2906ceb3885f6de89a3b3e60\": [{\"x\": 1.2198006438212339, \"y\": 9.201309707614168}, {\"x\": 1.0897044579970108, \"y\": 8.988191404987854}, {\"x\": 1.647915378046081, \"y\": 11.039626753418785}, {\"x\": 0.830754576670381, \"y\": 8.669865959097304}, {\"x\": 1.247934639247546, \"y\": 7.055090668327976}, {\"x\": 1.8784413299081755, \"y\": 9.890102030419008}, {\"x\": 0.30666817692531123, \"y\": 5.993787706951248}, {\"x\": 0.7116737577124599, \"y\": 6.196781520676983}, {\"x\": 0.5756569584079447, \"y\": 7.2869130583089134}, {\"x\": 1.4352606501780347, \"y\": 8.309427576033714}, {\"x\": 1.767103017904752, \"y\": 10.642051478293089}, {\"x\": 0.7118426875907331, \"y\": 9.6167838599892}, {\"x\": 0.12438050181328775, \"y\": 4.401919801423636}, {\"x\": 0.9982397744305924, \"y\": 8.24403141939456}, {\"x\": 1.7141023297708997, \"y\": 9.74693805585004}, {\"x\": 1.8900577994251766, \"y\": 6.6114601366188515}, {\"x\": 1.4223177711064057, \"y\": 9.634834054599406}, {\"x\": 0.32345866470797024, \"y\": 6.928043825913341}, {\"x\": 1.7655306720840656, \"y\": 9.953675160169832}, {\"x\": 0.8205797747328056, \"y\": 5.399592468327233}, {\"x\": 0.2690463843354891, \"y\": 4.802873010563867}, {\"x\": 0.7722475581531809, \"y\": 6.8725038104328435}, {\"x\": 1.4251189255451808, \"y\": 8.678591024590029}, {\"x\": 0.31282293489725466, \"y\": 6.170455207309783}, {\"x\": 0.2707676989516312, \"y\": 6.3991741677388205}, {\"x\": 1.522111679038506, \"y\": 9.107477345313141}, {\"x\": 1.7190735530460701, \"y\": 10.27623021408875}, {\"x\": 0.6460228150758589, \"y\": 6.542518425317097}, {\"x\": 0.44649166668561935, \"y\": 6.824901005700212}, {\"x\": 0.04997014227792085, \"y\": 3.6161333337262636}, {\"x\": 0.13945835146489527, \"y\": 4.634725050875814}, {\"x\": 1.0571551535903374, \"y\": 8.647070111819207}, {\"x\": 1.1588326938410958, \"y\": 8.877342538170389}, {\"x\": 0.3468221941989884, \"y\": 5.348965073340407}, {\"x\": 0.3132277837066968, \"y\": 5.634875804963522}, {\"x\": 1.2803475505588953, \"y\": 8.38896137439582}, {\"x\": 1.947148252253836, \"y\": 11.79781393703604}, {\"x\": 0.9343604765342854, \"y\": 8.940008748804328}, {\"x\": 1.3832212317540828, \"y\": 9.418855733930007}, {\"x\": 1.6176122752614621, \"y\": 9.338625853114511}, {\"x\": 1.0712594539503713, \"y\": 8.000115594584228}, {\"x\": 0.09143371154541535, \"y\": 5.313392599937331}, {\"x\": 0.8802188478435917, \"y\": 7.665412601537694}, {\"x\": 0.38261287581822145, \"y\": 5.224774378956612}, {\"x\": 0.04514322074058508, \"y\": 5.043907031848995}, {\"x\": 0.313967450268551, \"y\": 5.101486327504374}, {\"x\": 1.9904703075225654, \"y\": 13.128368706597755}, {\"x\": 1.1617115903376714, \"y\": 8.81444090969501}, {\"x\": 0.371149354523026, \"y\": 7.360208390795372}, {\"x\": 1.364981800228181, \"y\": 11.881631147300428}, {\"x\": 0.6128147933377939, \"y\": 5.036932053973047}, {\"x\": 1.2041538386060704, \"y\": 8.737046233368327}, {\"x\": 1.9360367505416942, \"y\": 11.650897773191687}, {\"x\": 0.03587424236028225, \"y\": 5.126181481596323}, {\"x\": 1.2383913994373215, \"y\": 7.047096863610438}, {\"x\": 0.9568550997491556, \"y\": 9.209393762014056}, {\"x\": 0.3805935065017181, \"y\": 6.556019675236521}, {\"x\": 0.06789577994039675, \"y\": 5.372393540768756}, {\"x\": 1.5055217135952133, \"y\": 8.502056660172894}, {\"x\": 0.6062316833329984, \"y\": 7.587850304688638}, {\"x\": 0.23769956576017925, \"y\": 4.835612001670793}, {\"x\": 1.373322723768607, \"y\": 6.8897234764072}, {\"x\": 0.8628842151812319, \"y\": 7.591318766022762}, {\"x\": 1.266971057474008, \"y\": 10.53057792495669}, {\"x\": 0.8427899496786673, \"y\": 7.673823883905783}, {\"x\": 1.9282021083342769, \"y\": 9.497892050663507}, {\"x\": 0.9038766130523939, \"y\": 7.93054175883963}, {\"x\": 0.8169006223780093, \"y\": 6.238238000585394}, {\"x\": 0.5764623603116261, \"y\": 5.3998303950314925}, {\"x\": 1.0420891789427964, \"y\": 9.206261607808681}, {\"x\": 1.5658774575523624, \"y\": 10.371693813619766}, {\"x\": 1.2916045873357813, \"y\": 9.359101936577835}, {\"x\": 1.831034093971852, \"y\": 10.840268904047555}, {\"x\": 0.015359486297369385, \"y\": 4.0692996970530135}, {\"x\": 0.5709712400181342, \"y\": 7.3276024588605}, {\"x\": 0.45982787985227813, \"y\": 5.1285859390597315}, {\"x\": 0.21010815539860572, \"y\": 4.979052314875355}, {\"x\": 0.38169112463535093, \"y\": 7.964711025368801}, {\"x\": 0.35309262182960643, \"y\": 6.911893199961103}, {\"x\": 0.1427402436935572, \"y\": 4.938240543302635}, {\"x\": 0.11626937985199937, \"y\": 6.182764627334548}, {\"x\": 1.7458596578007934, \"y\": 11.220598781658415}, {\"x\": 1.3553788600217513, \"y\": 9.616594880840251}, {\"x\": 1.0238022711574408, \"y\": 7.537710035962981}, {\"x\": 1.0650452789656912, \"y\": 9.24703675446977}, {\"x\": 0.9011133531050313, \"y\": 9.99663419852156}, {\"x\": 0.6008943986905146, \"y\": 7.44714647847754}, {\"x\": 1.6547190961626594, \"y\": 10.592220136863482}, {\"x\": 0.701048512164095, \"y\": 6.91471000143212}, {\"x\": 0.781440423703031, \"y\": 8.182840990386534}, {\"x\": 1.1680560593349874, \"y\": 9.08356524757865}, {\"x\": 0.5345180842656405, \"y\": 5.678030284191532}, {\"x\": 1.9899226868555397, \"y\": 12.082429083434846}, {\"x\": 1.6784449087881446, \"y\": 9.526028280375284}, {\"x\": 0.7824337486836277, \"y\": 8.680963741675596}, {\"x\": 1.5993979741970388, \"y\": 9.008775113159007}, {\"x\": 1.5958510521304072, \"y\": 11.64983449009849}, {\"x\": 1.4362883815501675, \"y\": 8.93087037865868}, {\"x\": 1.7656458451816255, \"y\": 8.81774720103989}, {\"x\": 0.5750490335196048, \"y\": 5.863001879829589}], \"data-d1fb7a47d11daad6673ec7b1705f5f63\": [{\"x\": 1.2198006438212339, \"y\": 8.73007713576964}, {\"x\": 1.0897044579970108, \"y\": 8.295630915655611}, {\"x\": 1.647915378046081, \"y\": 10.159733408017367}, {\"x\": 0.830754576670381, \"y\": 7.430887676423891}, {\"x\": 1.247934639247546, \"y\": 8.82402845257597}, {\"x\": 1.8784413299081755, \"y\": 10.929557117991408}, {\"x\": 0.30666817692531123, \"y\": 5.680741398576435}, {\"x\": 0.7116737577124599, \"y\": 7.033226427890046}, {\"x\": 0.5756569584079447, \"y\": 6.579008773809887}, {\"x\": 1.4352606501780347, \"y\": 9.44958927791599}, {\"x\": 1.767103017904752, \"y\": 10.557751376744553}, {\"x\": 0.7118426875907331, \"y\": 7.03379055624335}, {\"x\": 0.12438050181328775, \"y\": 5.072005708716977}, {\"x\": 0.9982397744305924, \"y\": 7.990191630117716}, {\"x\": 1.7141023297708997, \"y\": 10.380759649605793}, {\"x\": 1.8900577994251766, \"y\": 10.968349425704023}, {\"x\": 1.4223177711064057, \"y\": 9.406367527374744}, {\"x\": 0.32345866470797024, \"y\": 5.7368119428805}, {\"x\": 1.7655306720840656, \"y\": 10.552500648645328}, {\"x\": 0.8205797747328056, \"y\": 7.3969097068609635}, {\"x\": 0.2690463843354891, \"y\": 5.555106311882611}, {\"x\": 0.7722475581531809, \"y\": 7.2355079819009305}, {\"x\": 1.4251189255451808, \"y\": 9.415721767471574}, {\"x\": 0.31282293489725466, \"y\": 5.701294740088232}, {\"x\": 0.2707676989516312, \"y\": 5.560854509832244}, {\"x\": 1.522111679038506, \"y\": 9.739621617929611}, {\"x\": 1.7190735530460701, \"y\": 10.397360667902813}, {\"x\": 0.6460228150758589, \"y\": 6.813990147481865}, {\"x\": 0.44649166668561935, \"y\": 6.147671203048903}, {\"x\": 0.04997014227792085, \"y\": 4.8235180283698815}, {\"x\": 0.13945835146489527, \"y\": 5.1223570295269445}, {\"x\": 1.0571551535903374, \"y\": 8.186935013641033}, {\"x\": 1.1588326938410958, \"y\": 8.526479349645765}, {\"x\": 0.3468221941989884, \"y\": 5.814832655106527}, {\"x\": 0.3132277837066968, \"y\": 5.70264670159168}, {\"x\": 1.2803475505588953, \"y\": 8.932268880324813}, {\"x\": 1.947148252253836, \"y\": 11.158998607913876}, {\"x\": 0.9343604765342854, \"y\": 7.77687162124301}, {\"x\": 1.3832212317540828, \"y\": 9.275807637140105}, {\"x\": 1.6176122752614621, \"y\": 10.058538523793073}, {\"x\": 1.0712594539503713, \"y\": 8.2340352413683}, {\"x\": 0.09143371154541535, \"y\": 4.961982433199075}, {\"x\": 0.8802188478435917, \"y\": 7.596069810748197}, {\"x\": 0.38261287581822145, \"y\": 5.934352887358296}, {\"x\": 0.04514322074058508, \"y\": 4.807398894642811}, {\"x\": 0.313967450268551, \"y\": 5.70511676126258}, {\"x\": 1.9904703075225654, \"y\": 11.303669283997342}, {\"x\": 1.1617115903376714, \"y\": 8.536093203373396}, {\"x\": 0.371149354523026, \"y\": 5.896071338484731}, {\"x\": 1.364981800228181, \"y\": 9.214898456496153}, {\"x\": 0.6128147933377939, \"y\": 6.7030945095339565}, {\"x\": 1.2041538386060704, \"y\": 8.677825831555596}, {\"x\": 1.9360367505416942, \"y\": 11.12189260139995}, {\"x\": 0.03587424236028225, \"y\": 4.7764458532747724}, {\"x\": 1.2383913994373215, \"y\": 8.792159536228217}, {\"x\": 0.9568550997491556, \"y\": 7.851990687698915}, {\"x\": 0.3805935065017181, \"y\": 5.927609358629833}, {\"x\": 0.06789577994039675, \"y\": 4.883379318508845}, {\"x\": 1.5055217135952133, \"y\": 9.684220702576113}, {\"x\": 0.6062316833329984, \"y\": 6.681110719309373}, {\"x\": 0.23769956576017925, \"y\": 5.4504260189411715}, {\"x\": 1.373322723768607, \"y\": 9.242752330008589}, {\"x\": 0.8628842151812319, \"y\": 7.538182136413127}, {\"x\": 1.266971057474008, \"y\": 8.887599109091376}, {\"x\": 0.8427899496786673, \"y\": 7.471078880170457}, {\"x\": 1.9282021083342769, \"y\": 11.09572941551257}, {\"x\": 0.9038766130523939, \"y\": 7.675073100554066}, {\"x\": 0.8169006223780093, \"y\": 7.3846234601609675}, {\"x\": 0.5764623603116261, \"y\": 6.5816983516058105}, {\"x\": 1.0420891789427964, \"y\": 8.13662334849505}, {\"x\": 1.5658774575523624, \"y\": 9.885774073708621}, {\"x\": 1.2916045873357813, \"y\": 8.969860890009173}, {\"x\": 1.831034093971852, \"y\": 10.771244294843637}, {\"x\": 0.015359486297369385, \"y\": 4.707938401102917}, {\"x\": 0.5709712400181342, \"y\": 6.563361177148426}, {\"x\": 0.45982787985227813, \"y\": 6.192206462589241}, {\"x\": 0.21010815539860572, \"y\": 5.358286623283588}, {\"x\": 0.38169112463535093, \"y\": 5.931274770081093}, {\"x\": 0.35309262182960643, \"y\": 5.835772266559097}, {\"x\": 0.1427402436935572, \"y\": 5.1333166565485255}, {\"x\": 0.11626937985199937, \"y\": 5.044919239927441}, {\"x\": 1.7458596578007934, \"y\": 10.486810807340346}, {\"x\": 1.3553788600217513, \"y\": 9.18283017526075}, {\"x\": 1.0238022711574408, \"y\": 8.075555624529215}, {\"x\": 1.0650452789656912, \"y\": 8.213283481306178}, {\"x\": 0.9011133531050313, \"y\": 7.665845406200704}, {\"x\": 0.6008943986905146, \"y\": 6.6632872671927}, {\"x\": 1.6547190961626594, \"y\": 10.182453902086753}, {\"x\": 0.701048512164095, \"y\": 6.997744236486621}, {\"x\": 0.781440423703031, \"y\": 7.266206850317758}, {\"x\": 1.1680560593349874, \"y\": 8.557280070283074}, {\"x\": 0.5345180842656405, \"y\": 6.441628663412039}, {\"x\": 1.9899226868555397, \"y\": 11.301840546841534}, {\"x\": 1.6784449087881446, \"y\": 10.26168443101404}, {\"x\": 0.7824337486836277, \"y\": 7.269523982795016}, {\"x\": 1.5993979741970388, \"y\": 9.997713264395006}, {\"x\": 1.5958510521304072, \"y\": 9.985868590585973}, {\"x\": 1.4362883815501675, \"y\": 9.453021307895094}, {\"x\": 1.7656458451816255, \"y\": 10.552885260358398}, {\"x\": 0.5750490335196048, \"y\": 6.576978655338856}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.LayerChart(...)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predicted = w_0 + w_1 * X\n",
    "line = make_line_plot(X,y_predicted)\n",
    "\n",
    "#show the charts\n",
    "origin_chart + line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning_rate: 0.0010 => w_0 = [4.65664658], w_1 = [3.33942319]\n",
      "learning_rate: 0.1000 => w_0 = [4.90858171], w_1 = [3.11876371]\n",
      "learning_rate: 0.2000 => w_0 = [4.90858171], w_1 = [3.11876371]\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "initial_w_0 = 0\n",
    "initial_w_1 = 0\n",
    "num_iterations = 5000\n",
    "l_rates = [0.001, 0.1,0.2]\n",
    "learning_rate = 0.001\n",
    "all_params = []\n",
    "\n",
    "X,y = generate_data()\n",
    "data = (X,y)\n",
    "for i in range(0,len(l_rates)):\n",
    "    learning_rate = l_rates[i]\n",
    "    w_0,w_1 = gradient_descent(data,initial_w_0,initial_w_1,learning_rate,num_iterations)\n",
    "    all_params.append((w_0,w_1))\n",
    "    print(\"learning_rate: {:.4f} => w_0 = {}, w_1 = {}\".format(learning_rate,w_0,w_1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
